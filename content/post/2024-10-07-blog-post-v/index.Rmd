---
title: Blog Post 5
author: Kelly Olmos
date: '2024-10-07'
slug: blog-post-v
categories: []
tags: []
---
In this week's blog post I will explore how demographics provide insight into the electorate and election outcomes. 

```{r setup}
#' @title GOV 1347: Week 5 (Demographics) Laboratory Session
#' @author Matthew E. Dardet
#' @date October 2, 2024

####----------------------------------------------------------#
#### Preamble
####----------------------------------------------------------#

# Load libraries.
## install via `install.packages("name")`
library(car)
library(caret)
library(CVXR)
library(foreign)
library(glmnet)
library(haven)
library(janitor)
library(kableExtra)
library(maps)
library(mlr3)
library(randomForest)
library(ranger)
library(RColorBrewer)
library(sf)
library(tidyverse)
library(viridis)
library(usmap)


## set working directory here
# setwd("~")

```

```{r data-processing}

####----------------------------------------------------------#
#### Read, merge, and process data.
####----------------------------------------------------------#

# Read popular vote datasets. 
d_popvote <- read_csv("popvote_1948_2020.csv")
d_state_popvote <- read_csv("state_popvote_1948_2020.csv")

# Read elector distribution dataset. 
d_ec <- read_csv("corrected_ec_1948_2024.csv")

# Read and merge demographics data. 
d_demos <- read_csv("demographics.csv")[,-1]

# Read primary turnout data. 
d_turnout <- read_csv("turnout_1789_2020.csv")
d_state_turnout <- read_csv("state_turnout_1980_2022.csv")
d_state_turnout <- d_state_turnout |> 
  mutate(vep_turnout = as.numeric(str_remove(vep_turnout, "%"))/100) |> 
  select(year, state, vep_turnout)

# Read polling data. 
d_polls <- read_csv("national_polls_1968-2024.csv")
d_state_polls <- read_csv("state_polls_1968-2024.csv")

# Process state-level polling data. 
d_pollav_state <- d_state_polls |> 
  group_by(year, state, party) |>
  mutate(mean_pollav = mean(poll_support, na.rm = TRUE)) |>
  top_n(1, poll_date) |> 
  rename(latest_pollav = poll_support) |>
  select(-c(weeks_left, days_left, poll_date, candidate, before_convention)) |>
  pivot_wider(names_from = party, values_from = c(latest_pollav, mean_pollav))
```


```{r replication}
####----------------------------------------------------------#
#### Replication of Kim & Zilinsky (2023).
####----------------------------------------------------------#
                             
# Read processed ANES data. 
anes <- read_dta("anes_timeseries_cdf_stata_20220916.dta") # Total ANES Cumulative Data File. 

anes <- anes |> 
  mutate(year = VCF0004,
         pres_vote = case_when(VCF0704a == 1 ~ 1, 
                               VCF0704a == 2 ~ 2, 
                               .default = NA), 
         # Demographics
         age = VCF0101, 
         gender = VCF0104, # 1 = Male; 2 = Female; 3 = Other
         race = VCF0105b, # 1 = White non-Hispanic; 2 = Black non-Hispanic, 3 == Hispanic; 4 = Other or multiple races, non-Hispanic; 9 = missing/DK
         educ = VCF0110, # 0 = DK; 1 = Less than high school; 2. High school; 3 = Some college; 4 = College+ 
         income = VCF0114, # 1 = 0-16 percentile; 2 = 17-33 percentile; 3 = 34-67; 4 = 68 to 95; 5 = 96 to 100. 
         religion = VCF0128, # 0 = DK; 1 = Protestant; 2 = Catholic; 3 = Jewish; 4 = Other
         attend_church = case_when(
           VCF0004 < 1972 ~ as.double(as.character(VCF0131)),
           TRUE ~ as.double(as.character(VCF0130))
         ), # 1 = every week - regularly; 2 = almost every week - often; 3 = once or twice a month; 4 = a few times a year - seldom; 5 = never ; 6 = no religious preference
         southern = VCF0113,
         region = VCF0113, 
         work_status = VCF0118,
         homeowner = VCF0146, 
         married = VCF0147,
        
         # 7-point PID
         pid7 = VCF0301, # 0 = DK; 1 = Strong Democrat; 2 = Weak Democrat; 3 = Independent - Democrat; 4 = Independent - Independent; 5 = Independent - Republican; 6 = Weak Republican; 7 = Strong Republican
         
         # 3-point PID
         pid3 = VCF0303, # 0 = DK; 1 = Democrats; 2 = Independents; 3 = Republicans. 
         
         # 3-point ideology. 
         ideo = VCF0804 # 0, 9 = DK; 1 = Liberal; 2 = Moderate; 3 = Conservative
         ) |> 
  select(year, pres_vote, age, gender, race, educ, income, religion, attend_church, southern, region, work_status, homeowner, married, pid7, pid3, ideo)

# How well do demographics predict vote choice? 
anes_year <- anes[anes$year == 2016,] |> 
  select(-c(year, pid7, pid3, ideo)) |>
  mutate(pres_vote = factor(pres_vote, levels = c(1, 2), labels = c("Democrat", "Republican"))) |> 
  filter(!is.na(pres_vote)) |>
  clean_names()

n_features <- length(setdiff(names(anes_year), "pres_vote"))

set.seed(02138)
train.ind <- createDataPartition(anes_year$pres_vote, p = 0.8, list = FALSE)

anes_train <- anes_year[train.ind,]
anes_test <- anes_year[-train.ind,]

# LOGISTIC REGRESSION: 
logit_fit <- glm(pres_vote ~ ., 
                 family = "binomial", 
                 data = anes_train)

# In-sample goodness-of-fit. 
summary(logit_fit)

# In-sample accuracy.
logit.is <- factor(ifelse(predict(logit_fit, type = "response") > 0.5, 2, 1), levels = c(1, 2), labels = c("Democrat", "Republican"))

(cm.rf.logit.is <- confusionMatrix(logit.is, anes_train$pres_vote))

# Out-of-sample accuracy. 
logit_pred <- factor(ifelse(predict(logit_fit, anes_test, type = "response") > 0.5, 2, 1), levels = c(1, 2), labels = c("Democrat", "Republican"))

(cm.rf.logit.oos <- confusionMatrix(logit_pred, anes_test$pres_vote))

# RANDOM FOREST: 
rf_fit <- ranger(pres_vote ~ ., 
                 mtry = floor(n_features/3), 
                 respect.unordered.factors = "order", 
                 seed <- 02138,
                 classification = TRUE,
                 data = anes_train)

# In-sample accuracy.
(cm.rf.is <- confusionMatrix(rf_fit$predictions, anes_train$pres_vote))

# Out-of-sample accuracy. 
rf_pred <- predict(rf_fit, data = anes_test)
(cm.rf.oos <- confusionMatrix(rf_pred$predictions, anes_test$pres_vote))

# Can also write loop to compute values by year and replicate plots from Kim & Zilinsky's (2023) paper.
```
##Replicating Kim & Zilinsky (2023) 

Kim & Zilinsky (2023) co-authored a paper where they concluded that demographic information (five key attributes) about a voter can accurately predict a voter's choice with an accuracy of 63.9%. 

The replication above corroborates Kim & Zilinsky's findings. The 95% confidence interval ranges from 65.28% to 69.35%. I personally found this interesting because campaigns reach out to likely voters based on demographic information. It makes sense for a campaign with limited resources to make an educated guess on who to target based on a voter's demographics. Not only that, but when election predictions are being made, the demographics of the electorate are frequently cited. 

Demographic attributes like race are constantly in the headlines. In one CBS article, the headline reads "Kamala Harris turns to her faith in outreach to Black voters" One quote from the article highlights the importance of reaching out to Black voters, "Her focus underscores the importance for her in activating and persuading Black voters, the core of her party's electorate, by going to a stronghold within the community." 

In a country where race impacts the quality of life and experience of the voter, it makes sense for race to indicate a partisan preference. Especially when we consider political polarization in a two-party system. 

```{r voterfile}
####----------------------------------------------------------#
#### Voterfile loading/descriptives/analysis. 
####----------------------------------------------------------#

# Read and merge 1% voterfile data into one dataset. 
voterfile.sample.files <- list.files("state_1pc_samples_aug24")

# Florida example. 
tx_fl <- read_csv("state_1pc_samples_aug24/TX_sample.csv")

tx_fl <- tx_fl |>
  select(svi_vh_2020g, svi_vh_2022g, sii_age_range ,sii_gender, sii_race,sii_education_level, svi_vh_2024g) |>
  mutate(
    voted_2020 = ifelse(is.na(svi_vh_2020g), 0, 1),
    voted_2022 = ifelse(is.na(svi_vh_2022g), 0, 1),
    ) |>
  filter(!is.na(voted_2022) & !is.na(sii_age_range) & !is.na(sii_gender) &
           !is.na(sii_race) & !is.na(sii_education_level))


model_fit <- glm(voted_2020 ~ sii_age_range + sii_gender + sii_race + sii_education_level, family = binomial, data = tx_fl)

model_fit 

#The code below converts the log-odds into probabilities to make it easier to interpret and understand intuitively. It is modeled off R code from https://www.montana.edu/rotella/documents/502/Lecture_03_R_code.pdf

log_odds <- coef(model_fit)

#Converting log-odds to probabilities w/ plogis
probabilities <- plogis(log_odds)

#Making a table with log-odds and probabilities 
results <- data.frame(log_odds, probabilities)

#Present table w/ kable 
row.names(results) <- c("Intercept", "Age Range 30-39", "Age Range 40-49", "Age Range 50-64", "Age Range 65-74", "Age Range 75+", "Male", "Expansive", "Unknown1", "African-American", "Hispanic", "Native American", "Other", "Unknown2", "Caucasian", "Some College or Higher", "Completed College", "Completed Graduate School", "Attended Vocational/Technical")

colnames(results) <- c("Log odds", "Probabilities")
              
kable(results)

# Histograms, quantiles, prop tables, maps, etc. 

#Race 
race_percentages <- tx_fl |>
  mutate(
    sii_race = case_when(
      sii_race == "A" ~ "Asian",
      sii_race == "B" ~ "African-Amer.",
      sii_race == "H" ~ "Hispanic",
      sii_race == "N" ~ "Native Amer.",
      sii_race == "O" ~ "Other",
      sii_race == "U" ~ "Unknown",
      sii_race == "W" ~ "Caucasian"
    )) |>
  group_by(sii_race) |>
  summarise(count = n()) |>
  mutate(percentage = (count / sum(count)) * 100)

ggplot(race_percentages, aes(x = sii_race, y = percentage, fill = sii_race)) + geom_bar(stat = "identity") + labs(title = "Texas Voters and Race", x = "Race", y = "Percentage") + scale_y_continuous(breaks = seq(0, 100, by = 10))

#Education Level   
education_level_percentages <- tx_fl |>
  mutate(
    sii_education_level = case_when(
      sii_education_level == "A" ~ "High School",
      sii_education_level == "B" ~ "College",
      sii_education_level == "C" ~ "Graduate School",
      sii_education_level == "D" ~ "Vocational",
      sii_education_level == "E" ~ "Some College"
    )) |>
  group_by(sii_education_level) |>
  summarise(count = n()) |>
  mutate(percentage = (count / sum(count)) * 100)

ggplot(education_level_percentages, aes(x = sii_education_level, y = percentage, fill = sii_education_level)) + geom_bar(stat = "identity") + labs(title = "Texas Voters and Education", x = "Education Level of Texas Voters", y = "Percentage") + scale_y_continuous(breaks = seq(0, 100, by = 10))

#Gender 
gender_percentages <- tx_fl |>
  mutate(
    sii_gender = case_when(
      sii_gender == "M" ~ "Male",
      sii_gender == "F" ~ "Female",
      sii_gender == "U" ~ "Unknown",
      sii_gender == "X" ~ "Expansive"
    )) |>
  group_by(sii_gender) |>
  summarise(count = n()) |>
  mutate(percentage = (count / sum(count)) * 100)

kable(gender_percentages)

#Age Range 
age_range_percentages <- tx_fl |>
  mutate(
    sii_age_range = case_when(
      sii_age_range == "A" ~ "18-29",
      sii_age_range == "B" ~ "30-39",
      sii_age_range == "C" ~ "40-49",
      sii_age_range == "D" ~ "50-64",
      sii_age_range == "E" ~ "65-74",
      sii_age_range == "F" ~ "75+"
    )) |>
  group_by(sii_age_range) |>
  summarise(count = n()) |>
  mutate(percentage = (count / sum(count)) * 100)

kable(age_range_percentages)

# What state do you want to explore/analyze for 2024?
# TODO: 

```
##Analyzing the Texas Voter File 

To explore what insights we can obtain from voter demographics, I will analyze the Texas voter file. 

I ran a binomial logistic regression to estimate the relationship between whether a voter voted in 2020 and age range, race, gender, and education level. These are four out of the five attributes Kim and Zilinsky used for their random forest model. I don't have information about each voter's income in the file.

The binomial logistic regression models how the probability of success varies with the independent variables and helps determines whether the changes are statistically significant. In this case, success is defined as the person voting. The binomial logistic regression produces the logarithm of the odds as shown in the table. It's not simple to interpret and visualize the logarithm of the odds so I converted into probabilities. 

Essentially what I can takeaway from this regression is that the intercept is the baseline log-odds of voting for the reference group. In this case it is the age range 18-29, females, Asian voters, and the completed high school categories. The Unknowns in the table represent when the voter file had marked unknown race and gender for the voter. Since the unknowns do not represent a specific demographic I will ignore their associated values in my analysis. 

The intercept of -1.21 is the log odds of voting for the reference groups, which are age group 18-29, female gender, Asian, and completed high school. The log-odds can be converted to probabilities by raising e to the log-odds and and dividing it by 1 + e raised to the value of the log-odds. 

The age range odds and probabilities demonstrate that older citizens tend to vote in higher rates. In this sample of Texas voters, the age range with the highest turnout is 65 to 74. This is consistent with the available literature on age and voter turnout. 

Males and the other genders in this Texas voter file have negative log-odds which means that every other category in this sample have lower odds of voting compared to female voters. This too is also consistent with the available data on voter turnout (Gender differences in voter turnout)

All races except Hispanic have a positive coefficient, indicating that Hispanics have lower odds and probabilities of voting than the baseline group (Asians). It is unclear what demographics are represented under the Other category but the next group with highest odds are Caucasian. 

When looking at education, it is consistent with available data and literature that those who have completed college and graduate school are the groups of registered voters with the highest odds of voting. 

I have also included some graphs that provide descriptive statistics about the Texas electorate. The majority of registered voters in Texas is Caucasian, making up about 53% of registered voters. The next largest group is Hispanic voters, making up just under 30% of registered voters. 

Most of the Texas electorate completed high school and college. In regard to gender, there is an almost 50-50 split between female and male registered voters. The age range group leading in registered voters is 50-64, followed by 18-29. Although the 18-29 age range is known for being the age range with the lowest voter turnout. 

```{r simulation}

####----------------------------------------------------------#
#### Simulation examples. 
####----------------------------------------------------------#

# Merge data.
d <- d_pollav_state |> 
  left_join(d_state_popvote, by = c("year", "state")) |>  
  left_join(d_popvote |> filter(party == "democrat"), by = "year") |> 
  left_join(d_demos, by = c("year", "state")) |> 
  left_join(d_state_turnout, by = c("year", "state")) |> 
  filter(year >= 1980) |> 
  ungroup()

# Sequester states for which we have polling data for 2024. 
states.2024 <- unique(d$state[d$year == 2024])
states.2024 <- states.2024[-which(states.2024 == "Nebraska Cd 2")]

# Subset and split data.
d <- d |> 
  filter(state %in% states.2024)

d_train <- d |> 
  filter(year < 2024)
d_test <- d |> 
  filter(year == 2024)

# Example pooled model with turnout and demographics. 
mod_lm_dem <- lm(D_pv2p ~ D_pv2p_lag1 + D_pv2p_lag2 + latest_pollav_DEM + mean_pollav_DEM + vep_turnout + total_pop + white + black + american_indian + asian_pacific_islander + other_race + two_or_more_races + hispanic_white +
less_than_college + bachelors + graduate + incumbent + incumbent_party, data = d_train)

summary(mod_lm_dem)

mod_lm_rep <- lm(R_pv2p ~ R_pv2p_lag1 + R_pv2p_lag2 + latest_pollav_REP + mean_pollav_REP + vep_turnout + total_pop + white + black + american_indian + asian_pacific_islander + other_race + two_or_more_races + hispanic_white +
less_than_college + bachelors + graduate, data = d_train)

summary(mod_lm_rep)

# Most demographic variables and turnout are not significant for Democrats, but they are for Republicans.
# Problem: we do not have demographic data for 2024. 
# What can we do? 
# A few options: 
# (1.) Estimate state-level demographics from voterfile and plug in for 2024. 
# (2.) Interpolate Census demographics using a spline or some type of model. 
# (3.) Simulate plausible values for variables based on historical averages or more advanced model. 

# Simple simulation example: 
simp.vars <- c("D_pv2p_lag1", "D_pv2p_lag2", "latest_pollav_DEM", "mean_pollav_DEM", "R_pv2p_lag1", "R_pv2p_lag2", "latest_pollav_REP", "mean_pollav_REP", "vep_turnout")

mod_lm_dem_simp <- lm(D_pv2p ~ D_pv2p_lag1 + D_pv2p_lag2 + latest_pollav_DEM + mean_pollav_DEM + vep_turnout, data = d_train)

mod_lm_rep_simp <- lm(R_pv2p ~ R_pv2p_lag1 + R_pv2p_lag2 + latest_pollav_REP + mean_pollav_REP + vep_turnout, data = d_train)

# What data do we have for 2024? 
d_test |> select(all_of(simp.vars)) |> view()

# Add back in lagged vote share for 2024. 
t <- d |> 
  filter(year >= 2016) |> 
  arrange(year) |> 
  group_by(state) |> 
  mutate(
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1), 
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)) |> 
  filter(year == 2024) |> 
  select(state, year, D_pv2p, R_pv2p, D_pv2p_lag1, R_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag2) 

# Subset testing data to only relevant variables for our simple model. 
d_test_simp <- d_test |> 
  select(-c(R_pv2p, R_pv2p_lag1, R_pv2p_lag2, 
            D_pv2p, D_pv2p_lag1, D_pv2p_lag2)) |> 
  left_join(t, by = c("state", "year")) |> 
  select(state, year, all_of(simp.vars))

# Get average state-level turnout accross 2020, 2016, 2012.  
d_turnout_avg <- d_train |> 
  filter(year %in% c(2020, 2016, 2012)) |> 
  filter(state %in% unique(d_test_simp$state)) |> 
  group_by(state) |> 
  summarize(vep_turnout = mean(vep_turnout, na.rm = TRUE))

# Make predictions with simple average turnout. 
d_test_simp <- d_test_simp |> 
  left_join(d_turnout_avg, by = "state") |> 
  select(-vep_turnout.x) |> 
  rename(vep_turnout = vep_turnout.y)

simp_pred_dem <- predict(mod_lm_dem_simp, d_test_simp)
simp_pred_rep <- predict(mod_lm_rep_simp, d_test_simp)

# Create dataset to summarize winners and EC vote distributions. 
win_pred <- data.frame(state = d_test_simp$state,
                       year = rep(2024, length(d_test_simp$state)),
                       simp_pred_dem = simp_pred_dem,
                       simp_pred_rep = simp_pred_rep,
                       winner = ifelse(simp_pred_dem > simp_pred_rep, "Democrat", "Republican")) |>
  left_join(d_ec, by = c("state", "year"))

win_pred |> 
  filter(winner == "Democrat") |> 
  select(state)

win_pred |> 
  filter(winner == "Republican") |> 
  select(state)

win_pred |> 
  group_by(winner) |> 
  summarize(n = n(), ec = sum(electors))

# Now let's simulate this with varying levels of turnout and get both confidence intervals on our predictions
# and approximate win percentages for each state. 
m <- 1e4 # Number of simulations.
pred.mat <- data.frame(state = rep(d_test_simp$state, m),
                       year = rep(2024, m*length(d_test_simp$state)),
                       vep_turnout = rep(d_turnout_avg$vep_turnout, m),
                       simp_pred_dem = rep(simp_pred_dem, m),
                       simp_pred_rep = rep(simp_pred_rep, m))

j <- 1
for (i in 1:m) {
  print(i)
  vep_turnout <- sapply(d_turnout_avg$vep_turnout, function(mu) {
    rnorm(1, mean = mu, sd = 0.05) # Simulate turnout from Gaussian centered on state average with 5% SD.
  })

  d_test_samp <- d_test_simp
  d_test_samp$vep_turnout <- vep_turnout

  simp_pred_dem <- predict(mod_lm_dem_simp, d_test_samp)
  simp_pred_rep <- predict(mod_lm_rep_simp, d_test_samp)

  pred.mat$simp_pred_dem[j:(i*19)] <- simp_pred_dem
  pred.mat$simp_pred_rep[j:(i*19)] <- simp_pred_rep
  j <- j + 19 # Hack for filling out matrix.
}

pred.mat <- pred.mat |>
  mutate(winner = ifelse(simp_pred_dem > simp_pred_rep, "Democrat", "Republican"))

pred.mat |>
  group_by(state, winner) |>
  summarize(win_rate = n()/m) |>
  view()

# Now we can calculate confidence intervals for each state.
electoral_outcomes <- pred.mat |>
  group_by(state) |>
  summarize(mean_dem = mean(simp_pred_dem),
            mean_rep = mean(simp_pred_rep),
            sd_dem = sd(simp_pred_dem),
            sd_rep = sd(simp_pred_rep),
            lower_dem = mean_dem - 1.96*sd_dem,
            upper_dem = mean_dem + 1.96*sd_dem,
            lower_rep = mean_rep - 1.96*sd_rep,
            upper_rep = mean_rep + 1.96*sd_rep) |>
  view() |>
  mutate(
    winner = ifelse(mean_dem > mean_rep, "Democrat", "Republican")
  )

electoral_outcomes

#Since this only gives us the results for 19 states, it includes all swing states so a simple calculation with lagged vote will allow me to fill in the winner for the rest of the US
#list of all states 
all_states <- state.name

missing_states <- setdiff(all_states, unique(electoral_outcomes$state))
missing_states

#created a new data frame for the missing states 
missing_data <- d_state_popvote |>
  filter(state %in% missing_states) |>
  filter(year == 2020) |>
  select(state, D_pv2p_lag1, R_pv2p_lag1)

#Create the winner column based on lagged vote shares. Since these are not swing states, using the outcome from the last election reflects whethere it is a blue/red state
missing_data <- missing_data|>
  mutate(
    winner = ifelse(D_pv2p_lag1 > R_pv2p_lag1, "Democrat", "Republican")
  )

ec_2024 <- d_ec |>
  filter(year == 2024) |> 
  select(state, electors)
  


#Combine datasets 
all_states_pred <- bind_rows(electoral_outcomes, missing_data) |>
  left_join(ec_2024, by = "state")

winner <- all_states_pred |>
  group_by(winner) |>
  summarize(total_electors = sum(electors))

winner

#DC not included so add 3 for Dem electoral college count
election_results <- tibble(
  party = c("Democrat", "Republican"),
  total_electors = c(winner$total_electors[1] + 3, winner$total_electors[2])
)

kable(election_results)


plot_usmap(data = all_states_pred, regions = "states", values = "winner") + scale_fill_manual(
    values = c("Democrat" = "blue", "Republican" = "red"),
    name = "Predicted Winner"
  ) +
  labs(title = "Electoral College Predictions") 
```
##Simulation and Prediction for this Week 

My prediction for this week is based on a simple linear model that uses polling data, two-party lagged vote shares, and turnout data. 10,000 simulations are then run to account for variability in turnout. One of the benefits of simulating with turnout variability is that it provides a range of plausible turnout percentages which captures how changes in voter turnout across states can influence the election outcome. The final prediction is that Kamala Harris wins 319 electors and Trump wins 219. This model predicts that Harris will win in all the swing states which is an interesting result that I am hesitant about accepting but provokes thoughts about how to refine this model for future iterations.




##References 

“Gender Differences in Voter Turnout.” Center for American Women and Politics, cawp.rutgers.edu/facts/voters/gender-differences-voter-turnout. Accessed 28 Oct. 2024. 

Kim, Seo-young Silvia, and Jan Zilinsky. “Division Does Not Imply Predictability: Demographics Continue to Reveal Little about Voting and Partisanship.” Political Behavior, vol. 46, no. 1, 20 Aug. 2022, pp. 67–87, doi:10.1007/s11109-022-09816-z. 

Navarro, Aaron. “Kamala Harris Turns to Her Faith in Outreach to Black Voters.” CBS News, CBS Interactive, www.cbsnews.com/news/kamala-harris-faith-black-voter-outreach/. Accessed 27 Oct. 2024. 

